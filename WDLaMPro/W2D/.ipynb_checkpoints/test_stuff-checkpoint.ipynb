{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denitions of synsets for the word \"dog\":\n",
      "\n",
      "dog.n.01 \t\tDefinition: a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times\n",
      "frump.n.01 \t\tDefinition: a dull unattractive unpleasant girl or woman\n",
      "dog.n.03 \t\tDefinition: informal term for a man\n",
      "cad.n.01 \t\tDefinition: someone who is morally reprehensible\n",
      "frank.n.02 \t\tDefinition: a smooth-textured sausage of minced beef or pork usually smoked\n",
      "pawl.n.01 \t\tDefinition: a hinged catch that fits into a notch of a ratchet to move a wheel forward or prevent it from moving backward\n",
      "andiron.n.01 \t\tDefinition: metal supports for logs in a fireplace\n",
      "chase.v.01 \t\tDefinition: go after with the intent to catch\n",
      "\n",
      "\n",
      "Denitions of neighbors for the synset \"dog.n.01\":\n",
      "\n",
      "bitch.n.04 \t\tDefinition: female of any member of the dog family\n",
      "dog.n.01 \t\tDefinition: a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times\n",
      "fox.n.01 \t\tDefinition: alert carnivorous mammal with pointed muzzle and ears and a bushy tail\n",
      "hyena.n.01 \t\tDefinition: doglike nocturnal mammal of Africa and southern Asia that feeds chiefly on carrion\n",
      "jackal.n.01 \t\tDefinition: Old World nocturnal canine mammal closely related to the dog\n",
      "wild_dog.n.01 \t\tDefinition: any of various undomesticated mammals of the family Canidae that are thought to resemble domestic dogs as distinguished from jackals or wolves\n",
      "wolf.n.01 \t\tDefinition: any of various predatory carnivorous canine mammals of North America and Eurasia that usually hunt in packs\n",
      "dog.n.01 \t\tDefinition: a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times\n",
      "domestic_cat.n.01 \t\tDefinition: any domesticated member of the genus Felis\n",
      "feeder.n.01 \t\tDefinition: an animal being fattened or suitable for fattening\n",
      "head.n.02 \t\tDefinition: a single domestic animal\n",
      "stocker.n.01 \t\tDefinition: a domestic animal (especially a young steer or heifer) kept as stock until fattened or matured and suitable for a breeding establishment\n",
      "stray.n.01 \t\tDefinition: an animal that has strayed (especially a domestic animal)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "print(f'Denitions of synsets for the word \"dog\":\\n')\n",
    "for synset in wn.synsets('dog'):\n",
    "    print(f'{synset.name()} \\t\\tDefinition: {synset.definition().split(\";\")[0]}')\n",
    "\n",
    "dog = wn.synset('dog.n.01')\n",
    "print(f'\\n\\nDenitions of neighbors for the synset \".n.01\":\\n')\n",
    "for hypernym in dog.hypernyms():\n",
    "    print(f\\n'Hypernym of dog.n.01: {hypernym.name()}\\n')\n",
    "    for option in hypernym.hyponyms():\n",
    "        print(f'{option.name()} \\t\\tDefinition: {option.definition().split(\";\")[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# models = ['t5-small','t5-3b']\n",
    "# sentences = [\"India is one of the most\", \"Hello, my dog is really\", \"when i am very thirsty, I always drink\"]\n",
    "# top_n = 5\n",
    "\n",
    "# for model_name in models:\n",
    "#     tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "#     model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "    \n",
    "#     print(f'Using model {model_name}:\\n')\n",
    "\n",
    "#     for sentence in sentences:\n",
    "#         input_ids = tokenizer.encode(sentence, return_tensors=\"pt\")  # Batch size 1\n",
    "#         outputs = model(input_ids=input_ids, decoder_input_ids=input_ids)\n",
    "#         prediction_scores = outputs[0]\n",
    "\n",
    "#         sort_inds = torch.argsort(prediction_scores[0,-1,:], descending=True)\n",
    "#         for i in range(top_n):\n",
    "#             print(f'{i+1}) {tokenizer.decode(torch.cat([input_ids[0][:],  sort_inds[i].unsqueeze(0)], 0))}')\n",
    "\n",
    "#         print('\\n')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "input_ids = tokenizer.encode(\"qqp question1: What attributes would have made you highly desirable in ancient Rome? question2: How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER? \", return_tensors=\"pt\")  # Batch size 1\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) a\n",
      "2) big\n",
      "3) small\n",
      "4) bad\n",
      "5) large\n",
      "6) huge\n",
      "7) the\n",
      "8) co\n",
      "9) one\n",
      "10) massive\n",
      "11) very\n",
      "12) hard\n",
      "13) ,\n",
      "14) work\n",
      "15) more\n",
      "16) good\n",
      "17) of\n",
      "18) beer\n",
      "19) \n",
      "20) public\n",
      "21) great\n",
      "22) Co\n",
      "23) Greek\n",
      "24) major\n",
      "25) Crown\n",
      "26) wild\n",
      "27) company\n",
      "28) not\n",
      "29) new\n",
      "30) well\n",
      "31) team\n",
      "32) .\n",
      "33) no\n",
      "34) lot\n",
      "35) brand\n",
      "36) off\n",
      "37) widely\n",
      "38) famous\n",
      "39) an\n",
      "40) full\n",
      "41) world\n",
      "42) and\n",
      "43) popular\n",
      "44) bigger\n",
      "45) front\n",
      "46) poor\n",
      "47) much\n",
      "48) number\n",
      "49) star\n",
      "50) cock\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer, XLNetLMHeadModel\n",
    "import torch\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased')\n",
    "model = XLNetLMHeadModel.from_pretrained('xlnet-large-cased')\n",
    "\n",
    "# We show how to setup inputs to predict a next token using a bi-directional context.\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my <mask> is very friendly\", add_special_tokens=False)).unsqueeze(0)  # We will predict the masked token\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Microsoft is a <mask> company\", add_special_tokens=False)).unsqueeze(0)  # We will predict the masked token\n",
    "\n",
    "perm_mask = torch.zeros((1, input_ids.shape[1], input_ids.shape[1]), dtype=torch.float)\n",
    "perm_mask[:, :, 3] = 1.0  # Previous tokens don't see last token\n",
    "target_mapping = torch.zeros((1, 1, input_ids.shape[1]), dtype=torch.float)  # Shape [1, 1, seq_length] => let's predict one token\n",
    "target_mapping[0, 0, 3] = 1.0  # Our first (and only) prediction will be the last token of the sequence (the masked token)\n",
    "\n",
    "outputs = model(input_ids, perm_mask=perm_mask, target_mapping=target_mapping)\n",
    "next_token_logits = outputs[0]  # Output has shape [target_mapping.size(0), target_mapping.size(1), config.vocab_size]\n",
    "\n",
    "sort_inds = torch.argsort(next_token_logits[0,0,:], descending=True)\n",
    "for i in range(50):\n",
    "    print(f'{i+1}) {tokenizer.decode([sort_inds[i]])}')\n",
    "\n",
    "\n",
    "\n",
    "# max_seq_len = 24\n",
    "# tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased')\n",
    "# model = XLNetLMHeadModel.from_pretrained('xlnet-large-cased')\n",
    "# device = torch.device(f\"cuda:{2}\" if torch.cuda.is_available() else \"cpu\") \n",
    "# tokenizer.pad_token = '<pad>'\n",
    "# softmax = torch.nn.functional.softmax\n",
    "# model.to(device)\n",
    "\n",
    "# target_word = 'programming'\n",
    "# target_word2 = ' programming'\n",
    "# target_ids = tokenizer.encode(target_word)\n",
    "# # target_ids2 = tokenizer.encode(target_word2)\n",
    "# tokenized_word = tokenizer.tokenize(target_word)\n",
    "# # tokenized_word2 = tokenizer.tokenize(target_word2)\n",
    "\n",
    "\n",
    "\n",
    "# input_ids = list(tokenizer.encode(\"creating a sequence of instructions to enable the computer to do something is the definition of <mask>\", return_tensors=\"np\"))\n",
    "# print(len(input_ids))\n",
    "# mask_loc = input_ids.index(tokenizer.encode(tokenizer.mask_token))\n",
    "\n",
    "# input_mask = [1] * len(input_ids)\n",
    "            \n",
    "# id_padding = [tokenizer.pad_token_id] * (max_seq_len - len(input_ids))\n",
    "# mask_padding = [0] * (max_seq_len - len(input_ids))\n",
    "\n",
    "# input_ids = input_ids + id_padding\n",
    "# input_mask = input_mask + mask_padding\n",
    "    \n",
    "\n",
    "# input_ids = torch.tensor(input_ids).unsqueeze(0).to(device)\n",
    "# input_mask = torch.tensor(input_mask).unsqueeze(0).to(device)\n",
    "\n",
    "# print(tokenized_word)\n",
    "# # print(tokenized_word2)\n",
    "\n",
    "# # We show how to setup inputs to predict a next token using a bi-directional context.\n",
    "# perm_mask = torch.zeros((1, input_ids.shape[1], input_ids.shape[1]), dtype=torch.float).to(device)\n",
    "# perm_mask[:, :, mask_loc] = 1.0  # Previous tokens don't see last token\n",
    "# target_mapping = torch.zeros((1, 1, input_ids.shape[1]), dtype=torch.float).to(device)  # Shape [1, 1, seq_length] => let's predict one token\n",
    "# target_mapping[0, 0, mask_loc] = 1.0  # Our first (and only) prediction will be the last token of the sequence (the masked token)\n",
    "\n",
    "# outputs = model(input_ids, attention_mask=input_mask, perm_mask=perm_mask, target_mapping=target_mapping)\n",
    "# next_token_logits = outputs[0]  # Output has shape [target_mapping.size(0), target_mapping.size(1), config.vocab_size]\n",
    "\n",
    "# sort_inds = torch.argsort(next_token_logits[0,0,:], descending=True)\n",
    "# for i in range(50):\n",
    "#     print(f'{i+1}) {tokenizer.decode([sort_inds[i]])}')\n",
    "# # print(tokenizer.decode(torch.argmax(next_token_logits[0,0,:]).unsqueeze(-1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mis', '##cal', '##cula', '##tion']\n",
      "['mis', '##cal', '##cula', '##tion']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "word = ' miscalculation'\n",
    "x = tokenizer.tokenize(word,add_special_tokens=False)\n",
    "print(x)\n",
    "\n",
    "word = 'miscalculation'\n",
    "x = tokenizer.tokenize(word,add_special_tokens=False)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "max_seq_len = 18\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "device = torch.device(f\"cuda:{2}\" if torch.cuda.is_available() else \"cpu\") \n",
    "tokenizer.pad_token = '<pad>'\n",
    "softmax = torch.nn.functional.softmax\n",
    "model.to(device)\n",
    "\n",
    "target_word = ' programming'\n",
    "target_word2 = 'programming'\n",
    "target_ids = tokenizer.encode(target_word)\n",
    "target_ids2 = tokenizer.encode(target_word2)\n",
    "tokenized_word = tokenizer.tokenize(target_word)\n",
    "\n",
    "input_ids = list(tokenizer.encode(\"creating a sequence of instructions to enable the computer to do something is the definition of\", return_tensors=\"np\"))\n",
    "print(len(input_ids))\n",
    "\n",
    "input_mask = [1] * len(input_ids)\n",
    "            \n",
    "id_padding = [tokenizer.pad_token_id] * (max_seq_len - len(input_ids))\n",
    "mask_padding = [0] * (max_seq_len - len(input_ids))\n",
    "\n",
    "input_ids = input_ids + id_padding\n",
    "input_mask = input_mask + mask_padding\n",
    "    \n",
    "input_ids = torch.tensor(input_ids).unsqueeze(0).to(device)\n",
    "input_mask = torch.tensor(input_mask).unsqueeze(0).to(device)\n",
    "\n",
    "print(tokenized_word)\n",
    "context_scores = [1]*input_ids.shape[0]\n",
    "for target_id in target_ids:\n",
    "    output = model(input_ids=input_ids, attention_mask=input_mask)\n",
    "    for sample_no in range(input_ids.shape[0]):\n",
    "        target_location = sum(input_mask[sample_no]).item()\n",
    "        scores = output[0][sample_no, target_location-1, :] # get the scores for predicted words, targets are shifted by 1 index\n",
    "        print(tokenizer.decode(torch.cat((input_ids[0,:target_location], torch.tensor(tokenizer.encode('-')).to(device), torch.argmax(scores).unsqueeze(-1).to(device)),0)))\n",
    "        \n",
    "        probs = softmax(scores,dim=0)\n",
    "        sort_inds = torch.argsort(probs, descending=True)\n",
    "        for i in range(10):\n",
    "            print(f'{i+1}) {tokenizer.decode([sort_inds[i]])}')\n",
    "            \n",
    "        prob = softmax(scores,dim=0)[target_id]\n",
    "        prob2 = softmax(scores,dim=0)[target_ids2[0]]\n",
    "        print(f'Probability for {tokenizer.decode(target_ids[0])} is : {prob}')\n",
    "        print(f'Probability for {tokenizer.decode(target_ids2[0])} is : {prob2}')\n",
    "        context_scores[sample_no] = context_scores[sample_no]*(prob)\n",
    "          \n",
    "        if target_location == max_seq_len:\n",
    "            input_ids[sample_no] = torch.cat( (input_ids[sample_no, 1:], torch.tensor(target_id).unsqueeze(0).to(device)),0 ) \n",
    "        else:\n",
    "            input_ids[sample_no, target_location] = target_id\n",
    "            input_mask[sample_no, target_location] = 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# GPU memory test\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from nltk.corpus import wordnet as wn\n",
    "import definition_processor\n",
    "from definition_processor import DefinitionProcessor, get_patterns\n",
    "from evaluate import get_print_result, get_result\n",
    "\n",
    "max_seq_len = 48\n",
    "model_name = 'gpt2-xl'\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "# device = torch.device(f\"cuda:{2}\" if torch.cuda.is_available() else \"cpu\") \n",
    "# tokenizer.pad_token = '<pad>'\n",
    "# softmax = torch.nn.functional.softmax\n",
    "# model.to(device)\n",
    "\n",
    "def_processor = DefinitionProcessor(\n",
    "    model_cls='gpt-2',\n",
    "    pretrained_model=model_name,\n",
    "    gpu_id=2,\n",
    "    max_seq_len=max_seq_len,\n",
    "    multi_token=True\n",
    ")\n",
    "    \n",
    "syn = wn.synset('peasanthood.n.01')\n",
    "options = {}\n",
    "opt_count = 0\n",
    "for hypernym in syn.hypernyms():\n",
    "    for option in hypernym.hyponyms():\n",
    "        if option.name() not in options:\n",
    "            options[option.name()] = option.definition().split(';')[0]\n",
    "            if option.name() == syn.name():\n",
    "                answer = opt_count\n",
    "            opt_count += 1\n",
    "word = syn.name().split('.')[0].replace(\"_\", \" \")\n",
    "word = ' ' + word\n",
    "\n",
    "definitions = list(options.values())\n",
    "option_words = list(options.keys())\n",
    "pattern_count = len(get_patterns(def_processor.model_type))\n",
    "\n",
    "definitions = definitions[:2]\n",
    "print(f'Trying to process a word with {len(definitions)} definitions and {pattern_count} patterns (batch: {len(definitions)*pattern_count})')\n",
    "prediction_probs, tokenized_word = def_processor.process(word, None, definitions)\n",
    "\n",
    "# sample_results = []\n",
    "# for pattern_no in range(prediction_probs.shape[0]):\n",
    "#     sample_results.append(get_result(syn.name(), tokenized_word, prediction_probs[pattern_no], answer))\n",
    "\n",
    "# print(get_print_result(sample_results, definitions, option_words, answer, detailed=True))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/82115, elapsed time 10 seconds\n",
      "10000/82115, elapsed time 49 seconds\n",
      "15000/82115, elapsed time 105 seconds\n",
      "20000/82115, elapsed time 117 seconds\n",
      "25000/82115, elapsed time 130 seconds\n",
      "30000/82115, elapsed time 144 seconds\n",
      "35000/82115, elapsed time 153 seconds\n",
      "40000/82115, elapsed time 162 seconds\n",
      "45000/82115, elapsed time 176 seconds\n",
      "50000/82115, elapsed time 181 seconds\n",
      "55000/82115, elapsed time 201 seconds\n",
      "60000/82115, elapsed time 220 seconds\n",
      "65000/82115, elapsed time 257 seconds\n",
      "70000/82115, elapsed time 337 seconds\n",
      "75000/82115, elapsed time 356 seconds\n",
      "80000/82115, elapsed time 374 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 2645153 definitions are tokenized longler than 72 tokens\n",
      "6 of 2645153 definitions are tokenized longler than 64 tokens\n",
      "1660 of 2645153 definitions are tokenized longler than 48 tokens\n",
      "2771 of 2645153 definitions are tokenized longler than 46 tokens\n",
      "5307 of 2645153 definitions are tokenized longler than 44 tokens\n",
      "8878 of 2645153 definitions are tokenized longler than 42 tokens\n",
      "31895 of 2645153 definitions are tokenized longler than 36 tokens\n",
      "5000/13767, elapsed time 30 seconds\n",
      "10000/13767, elapsed time 44 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAaQUlEQVR4nO3df5BV5Z3n8fdnwN/JCGgPq0CEWRkTszUi06u4yaSMJIiaiJU1rm527Fhk2FSxmx9rKoPZH8wYrdKt1Ji4M3GGVUbMJCoxP2DVjdOLurupGZFWCREIS6sQICCt/DDqRMV894/zbb2SvvRtuH37x/N5Vd265zznOec8z+XyOaefe+49igjMzKwMvzXUDTAzs9Zx6JuZFcShb2ZWEIe+mVlBHPpmZgVx6JuZFcShb00h6U5JNzRY9wxJayX9UtLnJP2VpP/c4LqHrCvpK5Jub7Tdo5mkGyS9IGnXULfFhg/5On1rBkl3Atsj4j81UPcO4KWI+OIR7vN84G8jYvKRbGe4kvRp4DMR8cHDWPc9wCbgtIjY3ey22cjlM30bCqcB64e6EaPce4AXDyfwJY0dhPbYMOHQt8Mi6WxJT+YQzb3AsQct/1gO4eyT9PeSfj/LHwY+DPyFpJcl/V7t0JCk8yVtl3StpN2Sdkq6pma7d+awxQnA/wROze28LOlUSX8q6W9r6l8qaX2241FJ76tZtkXSlyStk7Rf0r2S3tGPg/r0x5I2Zp83SJqZ5e/Lbe/LfV1as86jkj5TM/9pST+umQ9Jn5W0Odf/S1XeB/wVcF72bV/Wvzj3/UtJOyR9qY92fgTorHlt7mzwtfgTSeuAVw4Ofkm3SfraQWUrJP2Heq+XDVMR4YcfA3oARwNbgS8CRwGXA28AN+Tys4HdwLnAGKAD2AIck8sfpRq26N3enTXrng8cAK7PbV8MvAqMr1N3+0Ft+1OqIR+A3wNeAT6a2/oy0A0cncu3AI8DpwITgI3AZ+v0+ZPADuCfAwJOp/qL5ajc5lfydbkA+CVwRp2+fhr4cc18APcD46jOznuAuX3VzbKdwB/m9HhgZp32vuO1afC1WAtMAY7rY3sfArbx9pDweOAfgVOH+v3ox8AePtO3wzGLKji+HhFvRMR9wJqa5QuAv46I1RHxZkQsA17L9RrxBnB9bvtB4GXgjMNo578CHoiIzoh4A/gacBzwL2rq3BoRv4iIPcD/AGbU2dZngP8aEWui0h0RW7NP7wJuiojXI+JhqhC/agDtvCki9kXEz4FHDtEGqF6bMyX9dkTsjYgnG9xHo6/Ftoj4xz7W/79UB6g/zPnLgX+IiF80uH8bJhz6djhOBXZERO1VAFtrpk8Drs1hhH05NDEl12vEixFxoGb+VapgPZx2vtWuiPg11dnqpJo6tVe2HGo/U4Bn6uxjW26719aD9tGfRtsA8C+p/vrZKul/SzqvwX008lpsq7dy/lvfw9sHs38NfLvBfdsw4tC3w7ETmCRJNWXvqZneBtwYEeNqHsdHxN1Nbkd/l579guoABEC2dwrVMM1AbQP+aZ19TJFU+3/pPTX7eAU4vmbZPxnAPn+jf/mXxjzgd4AfAssb3FYjr0V/r+fdwOWSTqMauvteg/u2YcShb4fjH6jG3T8n6ShJnwDOqVn+34HPSjo3P5Q8QdIlkt7d5HY8D5wk6cQ6y5cDl0iaLeko4FqqYaa/P4x93Q58SdIfZJ9Oz/BbTXV2/uV8Lc4HPk51VgzVOPknJB0v6XRg/gD2+TwwWdLRAJKOlvQpSSfmEM1LwK8PuYW3HfFrERFPAS9QvRYPRcS+AfTFhgmHvg1YRLwOfILqg8Y9VOPF369Z3gX8MfAXwF6qDww/PQjt+BnV2eezOYx06kHLNwH/BvhvVGH1ceDj2f6B7uu7wI3Ad6g+qP0hMCG39XHgotzHN4Grs20AtwCvUwX4MgY2JPIw1aWtuyS9kGV/BGyR9BLwWeBTDba/Wa/Fd4CP5LONQP5ylplZQXymb2ZWEIe+mVlBHPpmZgVx6JuZFWRY/7DSySefHFOnTh3qZpiZjShPPPHECxHR1teyYR36U6dOpaura6ibYWY2okjaWm+Zh3fMzAri0DczK4hD38ysIA59M7OCOPTNzAri0DczK4hD38ysIA59M7OCOPTNzAoyrL+Re6SmLnqgz/ItN13S4paYmQ0PPtM3MyuIQ9/MrCAOfTOzgjj0zcwK4tA3MyuIQ9/MrCANhb6kL0paL+lpSXdLOlbSNEmrJXVLulfS0Vn3mJzvzuVTa7ZzXZZvknTh4HTJzMzq6Tf0JU0CPge0R8Q/A8YAVwI3A7dExOnAXmB+rjIf2Jvlt2Q9JJ2Z670fmAt8U9KY5nbHzMwOpdHhnbHAcZLGAscDO4ELgPty+TLgspyel/Pk8tmSlOX3RMRrEfEc0A2cc+RdMDOzRvUb+hGxA/ga8HOqsN8PPAHsi4gDWW07MCmnJwHbct0DWf+k2vI+1nmLpAWSuiR19fT0HE6fzMysjkaGd8ZTnaVPA04FTqAanhkUEbEkItojor2trc+buZuZ2WFqZHjnI8BzEdETEW8A3wc+AIzL4R6AycCOnN4BTAHI5ScCL9aW97GOmZm1QCOh/3NglqTjc2x+NrABeAS4POt0ACtyemXOk8sfjojI8ivz6p5pwHTg8eZ0w8zMGtHvr2xGxGpJ9wFPAgeAp4AlwAPAPZJuyLI7cpU7gG9J6gb2UF2xQ0Ssl7Sc6oBxAFgYEW82uT9mZnYIDf20ckQsBhYfVPwsfVx9ExG/Aj5ZZzs3AjcOsI1mZtYk/kaumVlBHPpmZgVx6JuZFcShb2ZWEIe+mVlBHPpmZgVx6JuZFcShb2ZWEIe+mVlBHPpmZgVx6JuZFcShb2ZWEIe+mVlBHPpmZgVx6JuZFcShb2ZWkEZujH6GpLU1j5ckfUHSBEmdkjbn8/isL0m3SuqWtE7SzJptdWT9zZI66u/VzMwGQ7+hHxGbImJGRMwA/gB4FfgBsAhYFRHTgVU5D3AR1f1vpwMLgNsAJE2guvvWuVR33Frce6AwM7PWGOjwzmzgmYjYCswDlmX5MuCynJ4H3BWVx4Bxkk4BLgQ6I2JPROwFOoG5R9wDMzNr2EBD/0rg7pyeGBE7c3oXMDGnJwHbatbZnmX1yt9B0gJJXZK6enp6Btg8MzM7lIZDX9LRwKXAdw9eFhEBRDMaFBFLIqI9Itrb2tqasUkzM0sDOdO/CHgyIp7P+edz2IZ83p3lO4ApNetNzrJ65WZm1iIDCf2reHtoB2Al0HsFTgewoqb86ryKZxawP4eBHgLmSBqfH+DOyTIzM2uRsY1UknQC8FHg39YU3wQslzQf2ApckeUPAhcD3VRX+lwDEBF7JH0VWJP1ro+IPUfcAzMza1hDoR8RrwAnHVT2ItXVPAfXDWBhne0sBZYOvJlmZtYM/kaumVlBHPpmZgVx6JuZFcShb2ZWEIe+mVlBHPpmZgVx6JuZFcShb2ZWEIe+mVlBHPpmZgVx6JuZFcShb2ZWEIe+mVlBHPpmZgVx6JuZFaSh0Jc0TtJ9kn4maaOk8yRNkNQpaXM+j8+6knSrpG5J6yTNrNlOR9bfLKmj/h7NzGwwNHqm/w3gRxHxXuAsYCOwCFgVEdOBVTkP1b10p+djAXAbgKQJwGLgXOAcYHHvgcLMzFqj39CXdCLwIeAOgIh4PSL2AfOAZVltGXBZTs8D7orKY8C4vHH6hUBnROyJiL1AJzC3qb0xM7NDauRMfxrQA/yNpKck3Z73zJ2YNzwH2AVMzOlJwLaa9bdnWb3yd5C0QFKXpK6enp6B9cbMzA6pkdAfC8wEbouIs4FXeHsoB3jrvrjRjAZFxJKIaI+I9ra2tmZs0szMUiOhvx3YHhGrc/4+qoPA8zlsQz7vzuU7gCk160/OsnrlZmbWIv2GfkTsArZJOiOLZgMbgJVA7xU4HcCKnF4JXJ1X8cwC9ucw0EPAHEnj8wPcOVlmZmYtMrbBev8e+Lako4FngWuoDhjLJc0HtgJXZN0HgYuBbuDVrEtE7JH0VWBN1rs+IvY0pRdmZtaQhkI/ItYC7X0smt1H3QAW1tnOUmDpQBpoZmbN42/kmpkVxKFvZlYQh76ZWUEc+mZmBXHom5kVxKFvZlYQh76ZWUEc+mZmBXHom5kVxKFvZlYQh76ZWUEc+mZmBXHom5kVxKFvZlYQh76ZWUEc+mZmBWko9CVtkfRTSWsldWXZBEmdkjbn8/gsl6RbJXVLWidpZs12OrL+Zkkd9fZnZmaDYyBn+h+OiBkR0XsHrUXAqoiYDqzKeYCLgOn5WADcBtVBAlgMnAucAyzuPVCYmVlrHMnwzjxgWU4vAy6rKb8rKo8B4ySdAlwIdEbEnojYC3QCc49g/2ZmNkCNhn4AfyfpCUkLsmxiROzM6V3AxJyeBGyrWXd7ltUrfwdJCyR1Serq6elpsHlmZtaIhm6MDnwwInZI+h2gU9LPahdGREiKZjQoIpYASwDa29ubsk0zM6s0dKYfETvyeTfwA6ox+edz2IZ83p3VdwBTalafnGX1ys3MrEX6DX1JJ0h6d+80MAd4GlgJ9F6B0wGsyOmVwNV5Fc8sYH8OAz0EzJE0Pj/AnZNlZmbWIo0M70wEfiCpt/53IuJHktYAyyXNB7YCV2T9B4GLgW7gVeAagIjYI+mrwJqsd31E7GlaT8zMrF/9hn5EPAuc1Uf5i8DsPsoDWFhnW0uBpQNvppmZNYO/kWtmVhCHvplZQRz6ZmYFceibmRXEoW9mVhCHvplZQRz6ZmYFceibmRXEoW9mVhCHvplZQRz6ZmYFceibmRXEoW9mVhCHvplZQRz6ZmYFaTj0JY2R9JSk+3N+mqTVkrol3Svp6Cw/Jue7c/nUmm1cl+WbJF3Y7M6YmdmhDeRM//PAxpr5m4FbIuJ0YC8wP8vnA3uz/Jash6QzgSuB9wNzgW9KGnNkzTczs4FoKPQlTQYuAW7PeQEXAPdllWXAZTk9L+fJ5bOz/jzgnoh4LSKeo7qd4jnN6ISZmTWm0TP9rwNfBn6d8ycB+yLiQM5vBybl9CRgG0Au35/13yrvY523SFogqUtSV09PzwC6YmZm/ek39CV9DNgdEU+0oD1ExJKIaI+I9ra2tlbs0sysGP3eGB34AHCppIuBY4HfBr4BjJM0Ns/mJwM7sv4OYAqwXdJY4ETgxZryXrXrmJlZC/R7ph8R10XE5IiYSvVB7MMR8SngEeDyrNYBrMjplTlPLn84IiLLr8yre6YB04HHm9YTMzPrVyNn+vX8CXCPpBuAp4A7svwO4FuSuoE9VAcKImK9pOXABuAAsDAi3jyC/ZuZ2QANKPQj4lHg0Zx+lj6uvomIXwGfrLP+jcCNA22kmZk1h7+Ra2ZWEIe+mVlBHPpmZgVx6JuZFcShb2ZWEIe+mVlBHPpmZgVx6JuZFcShb2ZWEIe+mVlBHPpmZgVx6JuZFcShb2ZWEIe+mVlBHPpmZgVx6JuZFaSRG6MfK+lxST+RtF7Sn2X5NEmrJXVLulfS0Vl+TM535/KpNdu6Lss3SbpwsDplZmZ9a+RM/zXggog4C5gBzJU0C7gZuCUiTgf2AvOz/nxgb5bfkvWQdCbVrRPfD8wFvilpTDM7Y2Zmh9bIjdEjIl7O2aPyEcAFwH1Zvgy4LKfn5Ty5fLYkZfk9EfFaRDwHdNPH7RbNzGzwNDSmL2mMpLXAbqATeAbYFxEHssp2YFJOTwK2AeTy/cBJteV9rFO7rwWSuiR19fT0DLxHZmZWV0OhHxFvRsQMYDLV2fl7B6tBEbEkItojor2trW2wdmNmVqQBXb0TEfuAR4DzgHGSxuaiycCOnN4BTAHI5ScCL9aW97GOmZm1QCNX77RJGpfTxwEfBTZShf/lWa0DWJHTK3OeXP5wRESWX5lX90wDpgOPN6sjZmbWv7H9V+EUYFleafNbwPKIuF/SBuAeSTcATwF3ZP07gG9J6gb2UF2xQ0Ssl7Qc2AAcABZGxJvN7Y6ZmR1Kv6EfEeuAs/sof5Y+rr6JiF8Bn6yzrRuBGwfeTDMzawZ/I9fMrCAOfTOzgjj0zcwK4tA3MyuIQ9/MrCAOfTOzgjRynf6oM3XRA32Wb7npkha3xMystXymb2ZWEIe+mVlBHPpmZgVx6JuZFcShb2ZWEIe+mVlBHPpmZgVx6JuZFaSRO2dNkfSIpA2S1kv6fJZPkNQpaXM+j89ySbpVUrekdZJm1myrI+tvltRRb59mZjY4GjnTPwBcGxFnArOAhZLOBBYBqyJiOrAq5wEuoroV4nRgAXAbVAcJYDFwLtXNVxb3HijMzKw1+g39iNgZEU/m9C+p7o87CZgHLMtqy4DLcnoecFdUHqO6gfopwIVAZ0TsiYi9QCcwt6m9MTOzQxrQmL6kqVS3TlwNTIyInbloFzAxpycB22pW255l9crNzKxFGg59Se8Cvgd8ISJeql0WEQFEMxokaYGkLkldPT09zdikmZmlhkJf0lFUgf/tiPh+Fj+fwzbk8+4s3wFMqVl9cpbVK3+HiFgSEe0R0d7W1jaQvpiZWT8auXpHwB3Axoj485pFK4HeK3A6gBU15VfnVTyzgP05DPQQMEfS+PwAd06WmZlZizTye/ofAP4I+KmktVn2FeAmYLmk+cBW4Ipc9iBwMdANvApcAxAReyR9FViT9a6PiD1N6YWZmTWk39CPiB8DqrN4dh/1A1hYZ1tLgaUDaaCZmTWPv5FrZlYQh76ZWUEc+mZmBXHom5kVxKFvZlYQh76ZWUEc+mZmBXHom5kVxKFvZlYQh76ZWUEc+mZmBXHom5kVxKFvZlYQh76ZWUEc+mZmBXHom5kVpJHbJS6VtFvS0zVlEyR1Stqcz+OzXJJuldQtaZ2kmTXrdGT9zZI6+tqXmZkNrkbO9O8E5h5UtghYFRHTgVU5D3ARMD0fC4DboDpIAIuBc4FzgMW9BwozM2udfkM/Iv4PcPC9bOcBy3J6GXBZTfldUXkMGCfpFOBCoDMi9kTEXqCT3zyQmJnZIDvcMf2JEbEzp3cBE3N6ErCtpt72LKtX/hskLZDUJamrp6fnMJtnZmZ9OeIPcvNG6NGEtvRub0lEtEdEe1tbW7M2a2ZmHH7oP5/DNuTz7izfAUypqTc5y+qVm5lZCx1u6K8Eeq/A6QBW1JRfnVfxzAL25zDQQ8AcSePzA9w5WWZmZi00tr8Kku4GzgdOlrSd6iqcm4DlkuYDW4ErsvqDwMVAN/AqcA1AROyR9FVgTda7PiIO/nDYzMwGWb+hHxFX1Vk0u4+6ASyss52lwNIBtc7MzJrK38g1MyuIQ9/MrCAOfTOzgjj0zcwK0u8HuSWZuuiBPsu33HRJi1tiZjY4fKZvZlYQh76ZWUEc+mZmBXHom5kVxB/kNsAf8NpoVO99DX5vj2Y+0zczK4jP9FvIfzGY2VDzmb6ZWUF8pn8EfOZuZiONQ38YGw0HldHQB7PRxKFfCIevmcEQhL6kucA3gDHA7RFxU6vbMNId6lI7M7NDaWnoSxoD/CXwUWA7sEbSyojY0Mp2DLaBhrJD3MxapdVX75wDdEfEsxHxOnAPMK/FbTAzK1arh3cmAdtq5rcD59ZWkLQAWJCzL0vadAT7Oxl44QjWH04GpS+6udlbbMjJunnU/LvAKHyfDdH7otlG3b/LAOqfVm/BsPsgNyKWAEuasS1JXRHR3oxtDTX3ZfgaTf1xX4anZval1cM7O4ApNfOTs8zMzFqg1aG/BpguaZqko4ErgZUtboOZWbFaOrwTEQck/TvgIapLNpdGxPpB3GVThomGCfdl+BpN/XFfhqem9UUR0axtmZnZMOcfXDMzK4hD38ysIKMy9CXNlbRJUrekRUPdnkZIWippt6Sna8omSOqUtDmfx2e5JN2a/VsnaebQtfw3SZoi6RFJGyStl/T5LB9x/ZF0rKTHJf0k+/JnWT5N0ups8715YQKSjsn57lw+dSjb3xdJYyQ9Jen+nB/Jfdki6aeS1krqyrIR9z4DkDRO0n2SfiZpo6TzBqMvoy70a37q4SLgTOAqSWcObasacicw96CyRcCqiJgOrMp5qPo2PR8LgNta1MZGHQCujYgzgVnAwvw3GIn9eQ24ICLOAmYAcyXNAm4GbomI04G9wPysPx/Ym+W3ZL3h5vPAxpr5kdwXgA9HxIya69hH4vsMqt8k+1FEvBc4i+rfqPl9iYhR9QDOAx6qmb8OuG6o29Vg26cCT9fMbwJOyelTgE05/dfAVX3VG44PYAXV7y2N6P4AxwNPUn2L/AVg7MHvOaor087L6bFZT0Pd9po+TM7wuAC4H9BI7Uu2awtw8kFlI+59BpwIPHfw6zsYfRl1Z/r0/VMPk4aoLUdqYkTszOldwMScHjF9zCGBs4HVjND+5HDIWmA30Ak8A+yLiANZpba9b/Ull+8HTmptiw/p68CXgV/n/EmM3L4ABPB3kp7In3CBkfk+mwb0AH+TQ2+3SzqBQejLaAz9USmqw/mIur5W0ruA7wFfiIiXapeNpP5ExJsRMYPqLPkc4L1D3KTDIuljwO6IeGKo29JEH4yImVTDHQslfah24Qh6n40FZgK3RcTZwCu8PZQDNK8vozH0R9NPPTwv6RSAfN6d5cO+j5KOogr8b0fE97N4xPYHICL2AY9QDYGMk9T75cba9r7Vl1x+IvBii5tazweASyVtofqF2wuoxpFHYl8AiIgd+bwb+AHVQXkkvs+2A9sjYnXO30d1EGh6X0Zj6I+mn3pYCXTkdAfV2Hhv+dX5Cf4sYH/Nn4BDTpKAO4CNEfHnNYtGXH8ktUkal9PHUX02sZEq/C/Pagf3pbePlwMP5xnakIuI6yJickRMpfp/8XBEfIoR2BcASSdIenfvNDAHeJoR+D6LiF3ANklnZNFsYAOD0Zeh/gBjkD4UuRj4f1Rjr/9xqNvTYJvvBnYCb1Ad9edTjZ+uAjYD/wuYkHVFdYXSM8BPgfahbv9Bffkg1Z+h64C1+bh4JPYH+H3gqezL08B/yfLfBR4HuoHvAsdk+bE5353Lf3eo+1CnX+cD94/kvmS7f5KP9b3/10fi+yzbNwPoyvfaD4Hxg9EX/wyDmVlBRuPwjpmZ1eHQNzMriEPfzKwgDn0zs4I49M3MCuLQNzMriEPfzKwg/x8dSPdtLeZ1lgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 421249 definitions are tokenized longler than 72 tokens\n",
      "0 of 421249 definitions are tokenized longler than 64 tokens\n",
      "0 of 421249 definitions are tokenized longler than 48 tokens\n",
      "61 of 421249 definitions are tokenized longler than 46 tokens\n",
      "61 of 421249 definitions are tokenized longler than 44 tokens\n",
      "61 of 421249 definitions are tokenized longler than 42 tokens\n",
      "131 of 421249 definitions are tokenized longler than 36 tokens\n"
     ]
    }
   ],
   "source": [
    "# check definition lengths\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, BertTokenizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "word_types = ['n', 'v']\n",
    "\n",
    "for word_type in word_types:\n",
    "    all_synsets = list(wn.all_synsets(word_type))\n",
    "\n",
    "    t_init = time.time()\n",
    "    option_counts = []\n",
    "    tokenization_lengths = []\n",
    "    for sample_no, syn in enumerate(all_synsets):\n",
    "        options = {}\n",
    "        opt_count = 0\n",
    "        for hypernym in syn.hypernyms():\n",
    "            for option in hypernym.hyponyms():\n",
    "                if option.name() not in options:\n",
    "                    definition = option.definition().split(';')[0]\n",
    "                    tokenization_len = len(tokenizer.encode(definition)) + len(tokenizer.encode(\"is the definition of an\"))\n",
    "                    tokenization_lengths.append(tokenization_len)\n",
    "                    options[option.name()] = definition               \n",
    "                    opt_count += 1\n",
    "        option_counts.append(opt_count)\n",
    "\n",
    "        if (sample_no+1) % 5000 == 0:\n",
    "            elapsed = time.time() - t_init\n",
    "            print(f\"{sample_no+1}/{len(all_synsets)}, elapsed time {round(elapsed)} seconds\")\n",
    "\n",
    "    plt.hist(option_counts,bins=50)\n",
    "    plt.title(f'definition counts for {word_type}')\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(tokenization_lengths,bins=50)\n",
    "    plt.title(f'tokenization lengths for {word_type}')\n",
    "    plt.show()\n",
    "\n",
    "    tokenization_lengths = np.asarray(tokenization_lengths)\n",
    "    token_len_lims = [72, 64, 48, 46, 44, 42, 36]\n",
    "    for token_len_lim in token_len_lims:\n",
    "        print(f'{np.sum(tokenization_lengths>token_len_lim)} of {len(tokenization_lengths)} definitions are tokenized longler than {token_len_lim} tokens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verb: sigh.v.01,\t\tDefinition: heave or utter a sigh; breathe deeply and heavily\n",
      "Verb: exhale.v.01,\t\tDefinition: expel air\n",
      "Verb: hold.v.36,\t\tDefinition: keep from exhaling or expelling\n",
      "Verb: exhale.v.02,\t\tDefinition: give out (breath or an odor)\n",
      "Verb: sneeze.v.01,\t\tDefinition: exhale spasmodically, as when an irritant entered one's nose\n",
      "Verb: inhale.v.02,\t\tDefinition: draw in (air)\n",
      "Verb: pant.v.01,\t\tDefinition: breathe noisily, as when one is exhausted\n",
      "Verb: cough.v.01,\t\tDefinition: exhale abruptly, as when one has a chest cold or congestion\n",
      "Verb: hack.v.08,\t\tDefinition: cough spasmodically\n",
      "Verb: expectorate.v.02,\t\tDefinition: discharge (phlegm or sputum) from the lungs and out of the mouth\n",
      "Verb: snort.v.02,\t\tDefinition: make a snorting sound by exhaling hard\n",
      "Verb: wheeze.v.01,\t\tDefinition: breathe with difficulty\n",
      "Verb: puff.v.08,\t\tDefinition: blow hard and loudly\n",
      "Verb: blow.v.01,\t\tDefinition: exhale hard\n",
      "Verb: insufflate.v.03,\t\tDefinition: blow or breathe hard on or into\n",
      "Verb: yawn.v.01,\t\tDefinition: utter a yawn, as from lack of oxygen or when one is tired\n",
      "Verb: sniff.v.02,\t\tDefinition: inhale audibly through the nose\n",
      "Verb: blink.v.01,\t\tDefinition: briefly shut the eyes\n",
      "Verb: palpebrate.v.01,\t\tDefinition: wink or blink, especially repeatedly\n",
      "Verb: bat.v.02,\t\tDefinition: wink briefly\n"
     ]
    }
   ],
   "source": [
    "all_synsets = list(wn.all_synsets('v'))\n",
    "\n",
    "for syn in all_synsets[10:30]:\n",
    "    print(f'Verb: {syn.name()},\\t\\tDefinition: {syn.definition()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([sort_inds[i]])\n",
    "print(tokenizer.tokenize('This is a very nice programming course'))\n",
    "print(tokenizer.tokenize('programming'))\n",
    "\n",
    "x_all = tokenizer.encode(\"a mistake in calculating is the definition of miscalculation\", return_tensors=\"pt\")\n",
    "x_start = tokenizer.encode(\"a mistake in calculating is the definition of\", return_tensors=\"pt\")\n",
    "x_end = tokenizer.encode(\" miscalculation\", return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "print(x_all)\n",
    "print(x_start)\n",
    "print(x_end)\n",
    "\n",
    "print(tokenizer.decode(x_all[0]))\n",
    "print(tokenizer.decode(torch.cat( (x_start[0], x_end[0]), 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tattoo\n",
      "['T'] Prob: 0.01253421325236559\n",
      "['att'] Prob: 0.0008462361874990165\n",
      "['oo'] Prob: 0.0003813376824837178\n",
      "Average prob: 0.004587262403219938\n",
      "\n",
      "tattoo\n",
      "['t'] Prob: 0.0009132467093877494\n",
      "['att'] Prob: 0.0008462361874990165\n",
      "['oo'] Prob: 0.0003813376824837178\n",
      "Average Prob: 0.0007136068306863308\n",
      "\n",
      "Ornamentation\n",
      "['Or'] Prob: 0.0012971487594768405\n",
      "['n'] Prob: 0.0017240886809304357\n",
      "['ament'] Prob: 0.00011590198846533895\n",
      "['ation'] Prob: 0.0054183416068553925\n",
      "Average Prob: 0.0021388703025877476\n",
      "\n",
      "ornamentation\n",
      "['orn'] Prob: 4.928945600113366e-06\n",
      "['ament'] Prob: 0.00010094798926729709\n",
      "['ation'] Prob: 0.008340169675648212\n",
      "Average Prob: 0.002815348794683814\n",
      "\n",
      "Tessellation\n",
      "['Tes'] Prob: 3.313340812383103e-06\n",
      "['sell'] Prob: 8.196489034162369e-06\n",
      "['ation'] Prob: 0.008340169675648212\n",
      "Average Prob: 0.0027838933747261763\n",
      "\n",
      "tessellation\n",
      "['tes'] Prob: 2.9261147460601933e-07\n",
      "['sell'] Prob: 8.196489034162369e-06\n",
      "['ation'] Prob: 0.008340169675648212\n",
      "Average Prob: 0.0027828861493617296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForMaskedLM.from_pretrained('roberta-base')\n",
    "softmax = torch.nn.functional.softmax\n",
    "\n",
    "MASK_TOKEN = '<MASK>'\n",
    "\n",
    "option_1 = tokenizer.encode('Tattoo',add_special_tokens=False)\n",
    "option_2 = tokenizer.encode('tattoo',add_special_tokens=False)\n",
    "option_3 = tokenizer.encode('Ornamentation',add_special_tokens=False)\n",
    "option_4 = tokenizer.encode('ornamentation',add_special_tokens=False)\n",
    "option_5 = tokenizer.encode('Tessellation',add_special_tokens=False)\n",
    "option_6 = tokenizer.encode('tessellation',add_special_tokens=False)\n",
    "\n",
    "sentence = f'{MASK_TOKEN} is the practice of making a design on the skin by pricking and staining'\n",
    "\n",
    "\n",
    "\n",
    "masked_context = sentence.replace(MASK_TOKEN, ' '.join([tokenizer.mask_token]*len(option_1)))\n",
    "inp = torch.tensor(tokenizer.encode(masked_context, add_special_tokens=True)).unsqueeze(0)\n",
    "\n",
    "print(tokenizer.decode(option_1))\n",
    "out = model(inp)[0]\n",
    "probs = softmax(out[0,tuple(range(1,1+len(option_1))),:], dim=-1)\n",
    "prob = 0\n",
    "for i in range(len(option_1)):\n",
    "    new_prob = probs[i, option_1[i]]\n",
    "    print(f'{tokenizer.convert_ids_to_tokens([option_1[i]])} Prob: {new_prob}')\n",
    "    prob += new_prob\n",
    "\n",
    "# sorted_inds = torch.argsort(probs[0,:], descending=True)\n",
    "# print(f'Top 10 tokens with corresponding probs:')\n",
    "# for i in range(10):\n",
    "#     print(f'{i+1}) Token: {tokenizer.decode([sorted_inds[i]])}, prob: {probs[0, sorted_inds[i]]}')\n",
    "\n",
    "print(f'Average prob: {prob/len(option_1)}\\n') \n",
    "    \n",
    "    \n",
    "masked_context = sentence.replace(MASK_TOKEN, ' '.join([tokenizer.mask_token]*len(option_2)))\n",
    "inp = torch.tensor(tokenizer.encode(masked_context, add_special_tokens=True)).unsqueeze(0)\n",
    "\n",
    "print(tokenizer.decode(option_2))\n",
    "out = model(inp)[0]\n",
    "probs = softmax(out[0,tuple(range(1,1+len(option_2))),:], dim=-1)\n",
    "prob = 0\n",
    "for i in range(len(option_2)):\n",
    "    new_prob = probs[i, option_2[i]]\n",
    "    print(f'{tokenizer.convert_ids_to_tokens([option_2[i]])} Prob: {new_prob}')\n",
    "    prob += new_prob\n",
    "print(f'Average Prob: {prob/len(option_2)}\\n') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "masked_context = sentence.replace(MASK_TOKEN, ' '.join([tokenizer.mask_token]*len(option_3)))\n",
    "inp = torch.tensor(tokenizer.encode(masked_context, add_special_tokens=True)).unsqueeze(0)\n",
    "\n",
    "print(tokenizer.decode(option_3))\n",
    "out = model(inp)[0]\n",
    "probs = softmax(out[0,tuple(range(1,1+len(option_3))),:], dim=-1)\n",
    "prob = 0\n",
    "for i in range(len(option_3)):\n",
    "    new_prob = probs[i, option_3[i]]\n",
    "    print(f'{tokenizer.convert_ids_to_tokens([option_3[i]])} Prob: {new_prob}')\n",
    "    prob += new_prob\n",
    "print(f'Average Prob: {prob/len(option_3)}\\n') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "masked_context = sentence.replace(MASK_TOKEN, ' '.join([tokenizer.mask_token]*len(option_4)))\n",
    "inp = torch.tensor(tokenizer.encode(masked_context, add_special_tokens=True)).unsqueeze(0)\n",
    "\n",
    "print(tokenizer.decode(option_4))\n",
    "out = model(inp)[0]\n",
    "probs = softmax(out[0,tuple(range(1,1+len(option_4))),:], dim=-1)\n",
    "prob = 0\n",
    "for i in range(len(option_4)):\n",
    "    new_prob = probs[i, option_4[i]]\n",
    "    print(f'{tokenizer.convert_ids_to_tokens([option_4[i]])} Prob: {new_prob}')\n",
    "    prob += new_prob\n",
    "print(f'Average Prob: {prob/len(option_4)}\\n') \n",
    "\n",
    "\n",
    "\n",
    "masked_context = sentence.replace(MASK_TOKEN, ' '.join([tokenizer.mask_token]*len(option_5)))\n",
    "inp = torch.tensor(tokenizer.encode(masked_context, add_special_tokens=True)).unsqueeze(0)\n",
    "\n",
    "print(tokenizer.decode(option_5))\n",
    "out = model(inp)[0]\n",
    "probs = softmax(out[0,tuple(range(1,1+len(option_5))),:], dim=-1)\n",
    "prob = 0\n",
    "for i in range(len(option_5)):\n",
    "    new_prob = probs[i, option_5[i]]\n",
    "    print(f'{tokenizer.convert_ids_to_tokens([option_5[i]])} Prob: {new_prob}')\n",
    "    prob += new_prob\n",
    "print(f'Average Prob: {prob/len(option_5)}\\n') \n",
    "\n",
    "\n",
    "\n",
    "masked_context = sentence.replace(MASK_TOKEN, ' '.join([tokenizer.mask_token]*len(option_6)))\n",
    "inp = torch.tensor(tokenizer.encode(masked_context, add_special_tokens=True)).unsqueeze(0)\n",
    "\n",
    "print(tokenizer.decode(option_6))\n",
    "out = model(inp)[0]\n",
    "probs = softmax(out[0,tuple(range(1,1+len(option_6))),:], dim=-1)\n",
    "prob = 0\n",
    "for i in range(len(option_6)):\n",
    "    new_prob = probs[i, option_6[i]]\n",
    "    print(f'{tokenizer.convert_ids_to_tokens([option_6[i]])} Prob: {new_prob}')\n",
    "    prob += new_prob\n",
    "print(f'Average Prob: {prob/len(option_6)}\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " 'att',\n",
       " 'oo',\n",
       " 'is',\n",
       " 'the',\n",
       " 'practice',\n",
       " 'of',\n",
       " 'making',\n",
       " 'a',\n",
       " 'design',\n",
       " 'on',\n",
       " 'the',\n",
       " 'skin',\n",
       " 'by',\n",
       " 'pr',\n",
       " 'icking',\n",
       " 'and',\n",
       " 'st',\n",
       " 'aining']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('Tattoo is the practice of making a design on the skin by pricking and staining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tattoo'] Prob: 0.009664373472332954\n",
      "\n",
      "Average prob: 0.009664373472332954\n",
      "\n",
      "['or'] Prob: 0.0010223663412034512\n",
      "['##name'] Prob: 4.454912414075807e-05\n",
      "['##ntation'] Prob: 1.262182468053652e-05\n",
      "Average Prob: 0.00035984578425996006\n",
      "\n",
      "['tess'] Prob: 7.572545257517049e-08\n",
      "['##ella'] Prob: 3.0814267120149452e-06\n",
      "['##tion'] Prob: 0.0001136486025643535\n",
      "Average Prob: 3.893525354214944e-05\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "softmax = torch.nn.functional.softmax\n",
    "\n",
    "MASK_TOKEN = '<MASK>'\n",
    "\n",
    "option_1 = tokenizer.encode(' tattoo',add_special_tokens=False)\n",
    "option_2 = tokenizer.encode(' ornamentation',add_special_tokens=False)\n",
    "option_3 = tokenizer.encode(' tessellation',add_special_tokens=False)\n",
    "\n",
    "sentence = f'{MASK_TOKEN} is the practice of making a design on the skin by pricking and staining'\n",
    "\n",
    "\n",
    "\n",
    "masked_context = sentence.replace(MASK_TOKEN, ' '.join([tokenizer.mask_token]*len(option_1)))\n",
    "inp = torch.tensor(tokenizer.encode(masked_context, add_special_tokens=True)).unsqueeze(0)\n",
    "\n",
    "out = model(inp)[0]\n",
    "probs = softmax(out[0,tuple(range(1,1+len(option_1))),:], dim=-1)\n",
    "prob = 0\n",
    "for i in range(len(option_1)):\n",
    "    new_prob = probs[i, option_1[i]]\n",
    "    print(f'{tokenizer.convert_ids_to_tokens([option_1[i]])} Prob: {new_prob}')\n",
    "    prob += new_prob\n",
    "\n",
    "# print(inp)\n",
    "# print(out.shape)\n",
    "\n",
    "# sorted_inds = torch.argsort(probs[0,:], descending=True)\n",
    "# print(f'Top 10 tokens with corresponding probs:')\n",
    "# for i in range(10):\n",
    "#     print(f'{i+1}) Token: {tokenizer.decode([sorted_inds[i]])}, prob: {probs[0, sorted_inds[i]]}')\n",
    "\n",
    "print(f'\\nAverage prob: {prob/len(option_1)}\\n') \n",
    "    \n",
    "masked_context = sentence.replace(MASK_TOKEN, ' '.join([tokenizer.mask_token]*len(option_2)))\n",
    "inp = torch.tensor(tokenizer.encode(masked_context, add_special_tokens=True)).unsqueeze(0)\n",
    "\n",
    "out = model(inp)[0]\n",
    "probs = softmax(out[0,tuple(range(1,1+len(option_2))),:], dim=-1)\n",
    "prob = 0\n",
    "for i in range(len(option_2)):\n",
    "    new_prob = probs[i, option_2[i]]\n",
    "    print(f'{tokenizer.convert_ids_to_tokens([option_2[i]])} Prob: {new_prob}')\n",
    "    prob += new_prob\n",
    "print(f'Average Prob: {prob/len(option_2)}\\n') \n",
    "\n",
    "\n",
    "masked_context = sentence.replace(MASK_TOKEN, ' '.join([tokenizer.mask_token]*len(option_3)))\n",
    "inp = torch.tensor(tokenizer.encode(masked_context, add_special_tokens=True)).unsqueeze(0)\n",
    "\n",
    "out = model(inp)[0]\n",
    "probs = softmax(out[0,tuple(range(1,1+len(option_3))),:], dim=-1)\n",
    "prob = 0\n",
    "for i in range(len(option_3)):\n",
    "    new_prob = probs[i, option_3[i]]\n",
    "    print(f'{tokenizer.convert_ids_to_tokens([option_3[i]])} Prob: {new_prob}')\n",
    "    prob += new_prob\n",
    "print(f'Average Prob: {prob/len(option_3)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decapitalize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-7fd6ea39368d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tattoo is good'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decapitalize'"
     ]
    }
   ],
   "source": [
    "word = 'tattoo is good'\n",
    "word = word.capitalize()\n",
    "print(word.decapitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4264\n",
      "0.4764364976736464\n"
     ]
    }
   ],
   "source": [
    "from evaluate import SampleResult\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "pattern_count = 3\n",
    "max_token_count = 3\n",
    "\n",
    "results_data_dir = '/mounts/work/kerem/definition_classification_data/word_classificiations_from_definitions/roberta_again'\n",
    "with open(os.path.join(results_data_dir, f'roberta-base_n_results.pickle'), 'rb') as handle:\n",
    "    results = pickle.load(handle)\n",
    "    \n",
    "accuracies = []\n",
    "pred_scores = []\n",
    "option_counts = []\n",
    "for i in range(5):\n",
    "    pred_scores.append([])\n",
    "    accuracies.append([])\n",
    "    option_counts.append([])\n",
    "\n",
    "no = 0\n",
    "one_token_scores = []\n",
    "for key, value in results.items():\n",
    "    word = key.split('.')[0].replace(\"_\", \" \")\n",
    "    tokens = nltk.word_tokenize(word)\n",
    "    word = ' '.join(token.lower() for token in tokens)\n",
    "    token_count = len(value[0].tokenized_words[value[0].answer])\n",
    "\n",
    "    scores = []\n",
    "    correct = 0\n",
    "    for pattern_no in range(pattern_count):\n",
    "        score = value[pattern_no].prediction_score\n",
    "        scores.append(score)\n",
    "\n",
    "        if score == 1:                   \n",
    "            correct = 1\n",
    "\n",
    "    best_pred_score = max(scores)\n",
    "\n",
    "    pos = min(token_count, max_token_count+1)-1\n",
    "    if pos == 0:\n",
    "        one_token_scores.append(best_pred_score)\n",
    "#         print(f'Word: {word}, best prediction score: {best_pred_score}')\n",
    "        \n",
    "    accuracies[pos].append(correct)\n",
    "    pred_scores[pos].append(best_pred_score)\n",
    "    option_counts[pos].append(len(value[0].prediction_probs))\n",
    "\n",
    "    accuracies[-1].append(correct)\n",
    "    pred_scores[-1].append(best_pred_score)\n",
    "    option_counts[-1].append(len(value[0].prediction_probs))\n",
    "\n",
    "mean_pred_scores = [np.round(np.mean(scores), 2) for scores in pred_scores]\n",
    "mean_accuracies = [np.round(np.mean(acc)*100,2) for acc in accuracies]\n",
    "\n",
    "print(len(one_token_scores))\n",
    "print(np.mean(one_token_scores))\n",
    "# print(mean_pred_scores)\n",
    "# print(mean_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'adj'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-651ae4acb66a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mall_synsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_synsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'adj'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mvalid_cont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_synsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mounts/work/kerem/miniconda/envs/kerem_py37/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mall_synsets\u001b[0;34m(self, pos)\u001b[0m\n\u001b[1;32m   1662\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpos_tag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mADJ_SAT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mpos_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mADJ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1664\u001b[0;31m             \u001b[0mfileid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data.%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FILEMAP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1665\u001b[0m             \u001b[0mdata_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'adj'"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "all_synsets = list(wn.all_synsets('adj'))\n",
    "valid_cont = 0\n",
    "for sample_no, syn in enumerate(all_synsets):\n",
    "    options = []\n",
    "    for hypernym in syn.hypernyms():\n",
    "        for option in hypernym.hyponyms():\n",
    "            if option.name() not in options:\n",
    "                options.append(option.name())\n",
    "\n",
    "    if len(options) >= 5:\n",
    "        valid_cont += 1\n",
    "        print(f'\\nTarget: {syn.name()}')\n",
    "        print(f'Options:')\n",
    "        for i in range(len(options)):\n",
    "            print(f'{i+1}) {options[i]}')\n",
    "\n",
    "    if valid_cont == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('respire.v.01')\n",
      "[Synset('breathe.v.01')]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "word = all_synsets[2]\n",
    "print(word)\n",
    "print(word.hypernyms())\n",
    "print(word.hypernyms()[0].hyponyms())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('breathe.v.01.breathe'), Lemma('breathe.v.01.take_a_breath'), Lemma('breathe.v.01.respire'), Lemma('breathe.v.01.suspire')]\n",
      "[Lemma('respire.v.02.respire')]\n",
      "[Lemma('respire.v.01.respire')]\n",
      "[Lemma('choke.v.01.choke')]\n",
      "[Lemma('hyperventilate.v.02.hyperventilate')]\n",
      "[Lemma('hyperventilate.v.01.hyperventilate')]\n",
      "[Lemma('aspirate.v.03.aspirate')]\n",
      "[Lemma('burp.v.01.burp'), Lemma('burp.v.01.bubble'), Lemma('burp.v.01.belch'), Lemma('burp.v.01.eruct')]\n",
      "[Lemma('force_out.v.08.force_out')]\n",
      "[Lemma('hiccup.v.01.hiccup'), Lemma('hiccup.v.01.hiccough')]\n",
      "[Lemma('sigh.v.01.sigh'), Lemma('sigh.v.01.suspire')]\n",
      "[Lemma('exhale.v.01.exhale'), Lemma('exhale.v.01.expire'), Lemma('exhale.v.01.breathe_out')]\n",
      "[Lemma('hold.v.36.hold')]\n",
      "[Lemma('exhale.v.02.exhale'), Lemma('exhale.v.02.give_forth'), Lemma('exhale.v.02.emanate')]\n",
      "[Lemma('sneeze.v.01.sneeze')]\n",
      "[Lemma('inhale.v.02.inhale'), Lemma('inhale.v.02.inspire'), Lemma('inhale.v.02.breathe_in')]\n",
      "[Lemma('pant.v.01.pant'), Lemma('pant.v.01.puff'), Lemma('pant.v.01.gasp'), Lemma('pant.v.01.heave')]\n",
      "[Lemma('cough.v.01.cough')]\n",
      "[Lemma('hack.v.08.hack'), Lemma('hack.v.08.whoop')]\n",
      "[Lemma('expectorate.v.02.expectorate'), Lemma('expectorate.v.02.cough_up'), Lemma('expectorate.v.02.cough_out'), Lemma('expectorate.v.02.spit_up'), Lemma('expectorate.v.02.spit_out')]\n"
     ]
    }
   ],
   "source": [
    "for syn in all_synsets[:20]:\n",
    "    print(syn.lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
